---
title: NEW LINKS
draft: false
date_published: 2025-02-06
status: in-progress
tags:
  - links
  - reading
  - research

---

Links are posted monthly in chronological order and include any articles, papers, or essays that I find pertinent to my current research and writing. 

</br>

# 2025

----

## JUNE

- [Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task](https://arxiv.org/abs/2506.08872)
  - The study investigates the neural underpinnings of creative writing across different participant groups: "Brain-only" (unassisted), "LLM" (Large Language Model-assisted), and "Search Engine" (search engine-assisted). A primary focus is on Delta band connectivity, which consistently shows the most significant disparities between groups. The Brain-only group demonstrates significantly higher and more widespread Delta band activity, indicating greater engagement of deep, slow integrative brain processes, multisensory integration, and internally-driven thought during unassisted writing. Conversely, LLM and Search Engine groups exhibit more externally anchored or intermittently guided cognitive engagement, with notably weaker delta interactions.
  - N-gram analysis complements these neurological findings, revealing distinct linguistic patterns across groups for different topics. The "Brain-only" group tends to use n-grams reflecting internal thought processes and prosocial framing, while LLM and Search Engine groups show patterns indicative of external sourcing or more direct task-oriented language. The study also tracks changes in brain connectivity patterns across sessions, noting a general trend of increasing connectivity in later sessions for both Brain-only and LLM groups, suggesting adaptation to the task

- [Ultrafast coherent dynamics of microring modulators](https://www.nature.com/articles/s41566-025-01686-1)
  - Next-generation computing clusters require ultra-high-bandwidth optical interconnects to support large-scale artificial-intelligence applications. These electronic–photonic co-integrated systems necessitate densely integrated high-speed electro-optical converters. In this context, microring modulators (MRMs) emerge as a promising solution, prized for their exceptional compactness and energy efficiency.

- [Hitchhiker’s Guide to RAG: From Tiny Files to Tolstoy with OpenAI’s API and LangChain](https://towardsdatascience.com/hitchhikers-guide-to-rag-from-tiny-files-to-tolstoy-with-openais-api-and-langchain/)
  - Scaling a simple RAG pipeline from simple notes to full books

- [goose](https://github.com/block/goose)
  - an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM

- [If--](https://www.poetryfoundation.org/poems/46473/if---)
  - Kipling’s poem “If—” is essentially a father’s advice to his son (and, by extension, to any young person) on how to live a balanced, honorable life. Written in 1895 and later included in his 1910 collection Rewards and Fairies, it lays out a series of “if” scenarios—tests of character—and promises the ultimate reward (“you’ll be a Man, my son!”) if you can meet them all.

- [bitchat-android](https://github.com/permissionlesstech/bitchat-android)
  - bluetooth mesh chat, IRC vibes

- [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
  - Success on benchmarks only demonstrates potemkin understanding: the illusion of understanding driven by answers irreconcilable with how any human would interpret a concept.

- [The Best Tacit Knowledge Videos on Every Subject](https://www.lesswrong.com/posts/SXJGSPeQWbACveJhs/the-best-tacit-knowledge-videos-on-every-subject)


## MAY

* [Orienting Toward Wizard Power](https://www.lesswrong.com/posts/Wg6ptgi2DupFuAnXG/orienting-toward-wizard-power), Wentworth 2025
* [Neural Thermodynamic Laws for Large Language Model Training](https://arxiv.org/pdf/2505.10559), Tegmark, et al 2025
* [The ZINGULARITY framework for Bayesian artificial neural networks](https://www.aanda.org/10.1051/0004-6361/202553785), Janssen 2025
* [How to Generate Synthetic Data: A Comprehensive Guide Using Bayesian Sampling and Univariate Distributions](https://towardsdatascience.com/how-to-generate-synthetic-data-a-comprehensive-guide-using-bayesian-sampling-and-univariate-distributions/), 2025
* [Synthetic Data RL: Task Definition Is All You Need](https://huggingface.co/papers/2505.17063), Guo 2025
* [[https://arxiv.org/abs/2503.23278 | Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions]]
* [[https://sakana.ai/ctm/ | Continuous Thought Machines]]
  * Paper: [[https://arxiv.org/abs/2505.05522 | Continuous Thought Machines]]



## APRIL

* [[https://danieljeffries.substack.com/p/how-to-build-an-american-deepseek | How To build an American DeepSeek]] Jeffries 2025
* [[https://ai-2027.com/ | AI 2027]], [[https://ai-futures.org/ | AI Futures]] 2025
* [[https://www.lesswrong.com/posts/CqHMdLcdupf7y5buK/an-optimistic-2027-timeline?utm_source=substack&utm_medium=email | An Optimistic 2027 Timeline]], Yitz 2025
* [[https://www.lesswrong.com/posts/TpSFoqoG2M5MAAesg/ai-2027-what-superintelligence-looks-like-1#August_2027__The_Geopolitics_of_Superintelligence | AI 2027: What Superintelligence Looks Like]], Kokotajlo et al, 2025
* [[https://arxiv.org/abs/2504.01849?utm_source=substack&utm_medium=email# | An Approach to Technical AGI Safety and Security]], 2025
* [[https://www.writingruxandrabio.com/p/scott-alexander-was-right-doubling?utm_campaign=posts-open-in-app&triedRedirect=true | Scott Alexander was right: doubling down]], Teslo 2025
* [[https://huggingface.co/blog/tiny-agents | Tiny Agents: a MCP-powered agent in 50 lines of code]], Chaumond 2025
* [[https://www.researchgate.net/publication/221618539_Optimal_Brain_Damage | Optimal Brain Damage]], Lecun et al, 1989
* [[https://samkriss.substack.com/p/the-cacophony?manualredirect=&utm_campaign=posts-open-in-app&triedRedirect=true | The Cacophony]], Kriss 2025
* [[https://www.astralcodexten.com/p/theres-a-time-for-everyone?utm_campaign=posts-open-in-app&triedRedirect=true | There's A Time For Everyone]], ACX 2022
* [[https://medium.com/deep-code/sensemaking-in-2025-trump-tariffs-edition-7e43e5564b68 | Sensemaking in 2025: Trump Tariffs Edition]], Hall 2025


## MARCH

* re-read: [[https://contraptions.venkateshrao.com/p/the-extended-internet-universe | The Extended Internet Universe]], Venkatash Rao 2019
* [[https://www.ribbonfarm.com/2024/10/10/ribbonfarm-is-retiring/ | Ribbonfarm is Retiring]], Rao 2024
* [[https://huggingface.co/papers/2503.05592 | R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning]] 2025
* [[https://blogs.dickinson.edu/dcc/2013/03/25/vocabulary-study-with-mnemosyne/ | Vocabulary Study with Mnemosyne]]
* [[https://www.lesswrong.com/posts/xcMngBervaSCgL9cu/levels-of-friction | Levels of Friction]], Zvi 2025
* [On Writing #1](https://substack.com/@thezvi/p-155272667), Zvi 2025
* [[https://www.hbs.edu/ris/Publication%20Files/24-038_51f8444f-502c-4139-8bf2-56eb4b65c58a.pdf#page=31.22 | The Value of Open Source Software]], Hoffman et al 2024
* [[https://scholars-stage.org/on-the-tolkienic-hero/ | On the Tolkienic Hero]] 2019
* [[https://gwern.net/llm-writing | Writing for LLMs So They Listen]], Gwern 2024
* [[https://www.nature.com/articles/s41587-025-02584-1 | An open letter to graduate students and other procrastinators: it’s time to write]] Hazelett 2025


## FEBRUARY

Much of my time this month has been spent on researching tools that support the development of this site and implementing visual and basic quality-of-life features to establish a solid foundation for the future. 

- [[https://nxnjz.net/2019/09/how-to-install-pmwiki-on-debian-10-nginx-php-fpm/ | How to Install PmWiki on Debian 10 / Nginx / PHP-FPM]] 
- [[https://www.pmwiki.org/wiki/Cookbook/ImagePopup | Pmwiki - ImagePopup]]
- [[https://www.perplexity.ai/hub/blog/introducing-perplexity-deep-research | Introducing Perplexity Deep Research]]
- [[https://old.reddit.com/r/MachineLearning/comments/1ielwh5/d_deepseek_schmidhuber_did_it_first/ | DeepSeek? Schmidhuber did it first]]  ref: [[https://x.com/hardmaru/status/1885490494178025900 | @hardmaru]]
  - [[https://arxiv.org/abs/1511.09249 | On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models]]
  - [[https://arxiv.org/abs/1802.08864 | One Big Net For Everything]]
  - [[https://gwern.net/doc/ai/nn/rnn/1992-schmidhuber.pdf | Learning complex, extended sequences using the principle of history compression]]
  - [[https://people.idsia.ch/~juergen/world-models-planning-curiosity-fki-1990.html | 1990: Planning & Reinforcement Learning with Recurrent World Models and Artificial Curiosity]]
  - [[https://people.idsia.ch/~juergen/very-deep-learning-1991.html | 1991: First very deep learning with unsupervised pre-training]]
- [[https://arxiv.org/abs/2501.12948 | DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning]]
- [[https://gwern.net/book-writing | Why To Not Write A Book, Gwern]] 2024
- [[https://gwern.net/design#tags | Design of This Website, Gwern]] 2023
- [[https://edwardtufte.github.io/tufte-css/ | Tufte CSS, David Liepmann]]
- [[https://www.lesswrong.com/posts/DfrSZaf3JC8vJdbZL/how-to-make-superbabies | How To Make Superbabies, LessWrong Feb]] 2025